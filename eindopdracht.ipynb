{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eindopdracht Advanced Datamining\n",
    "\n",
    "## Studiejaar 2019-2020, 1e gelegenheid\n",
    "\n",
    "1. [Inleiding](#Inleiding)\n",
    "2. [Deel A](#Deel_A)\n",
    "3. [Deel B](#Deel_B)\n",
    "3. [Afsluiting](#Afsluiting)\n",
    "\n",
    "### <a id='Inleiding'>Inleiding</a>\n",
    "\n",
    "Dit is de *eindopdracht* behorende bij het vak *Advanced Datamining* (BFVH4DMN2) voor het *studiejaar 2019-2020 (1e gelegenheid)*. Op BlackBoard tref je eveneens een module `data.py` aan die diverse functies bevat die helpen bij het genereren en het visualiseren van de gebruikte datasets, en een bijbehorend data-bestand `MNIST-mini.zip`.\n",
    "\n",
    "Gebruik de `model` module die je in werkcollegeopdrachten 1, 2, 3, 4, en 5 & 6 hebt gemaakt om de onderstaande opdrachten uit te voeren. Deze eindopdracht bestaat uit twee delen:\n",
    "\n",
    "- in **Deel A** worden een aantal cellen code gedraaid die als het goed is onmiddellijk zouden moeten werken met je model;\n",
    "\n",
    "- in **Deel B** wordt je gevraagd om je gemaakte model zelf toe te passen, maar hoef je je module als het goed is niet te wijzigen.\n",
    "\n",
    "<div class=\"alert alert-danger\">**Waarschuwing:**<br />Je code mag gebruik maken van alle functies uit de [Python Standard Library](https://docs.python.org/3/library/) (zoals `math`, `random`, `itertools`, enzovoorts); het is *niet* toegestaan om functies toe te passen uit bestaande machine learning modules (zoals `sklearn`, `keras`, `tensorflow`, enzovoorts).</div>\n",
    "\n",
    "Eerst zetten we weer wat initialisatie op en importeren we naast de `data` en `model` modules enkele onderdelen van `pandas`, `numpy`, en `time`. Plaats de cursor in de cel hieronder en druk op Ctrl+Enter (of Shift+Enter om meteen naar de volgende cel te gaan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pandas import DataFrame, __version__\n",
    "print(f'Using pandas version {__version__}')\n",
    "\n",
    "from numpy import array, __version__\n",
    "print(f'Using numpy version {__version__}')\n",
    "\n",
    "from time import time\n",
    "\n",
    "import model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Deel_A'>Deel A</a>\n",
    "\n",
    "Hieronder staan een aantal fragmenten code die je model *ongewijzigd* dient te kunnen uitvoeren. Voor verdere details omtrent deze gevraagde functionaliteiten, zie zonodig de werkcollege-opdrachten en/of de syllabus.\n",
    "\n",
    "#### Activatiefuncties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activations = [model.linear, model.tanh, model.softsign, model.sigmoid, model.softplus, model.relu, model.sign]\n",
    "my_arguments =  [-1000, -1, 0, 1, 1000]\n",
    "my_table = [[φ(a) for a in my_arguments] for φ in my_activations]\n",
    "my_columns = [f'φ({a})' for a in my_arguments]\n",
    "my_rows = [φ.__name__ for φ in my_activations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph(my_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph([model.derivative(φ) for φ in my_activations if φ != model.sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(my_table, columns=my_columns).set_index(array(my_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lossfuncties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_losses = [model.mean_squared_error, model.mean_absolute_error, model.categorical_crossentropy, model.binary_crossentropy, model.hinge]\n",
    "my_arguments =  [0.01, 0.1, 0.5, 0.9, 0.99]\n",
    "my_table = [[L(a, 1.0) for a in my_arguments] for L in my_losses]\n",
    "my_columns = [f'L({a}; 1)' for a in my_arguments]\n",
    "my_rows = [L.__name__ for L in my_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.graph(my_losses, 1.0, xlim=(1e-2, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(my_table, columns=my_columns).set_index(array(my_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: single-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('nominal')\n",
    "my_model = model.Perceptron(dim=2)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: binomiale logistische regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear(outcome='nominal', noise=1.0)\n",
    "ys = [(y + 1.0) / 2.0 for y in ys]   # Convert labels -1/+1 to 0/1\n",
    "my_model = model.Neuron(dim=2, activation=model.sigmoid, loss=model.binary_crossentropy)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificatie: multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.fractal(4)\n",
    "my_model = model.InputLayer(2) + \\\n",
    "           model.Dense(20) + \\\n",
    "           model.Activation(20, activation=model.tanh) + \\\n",
    "           model.Dense(10) + \\\n",
    "           model.Activation(10, activation=model.tanh) + \\\n",
    "           model.Dense(4) + \\\n",
    "           model.Softmax(4) + \\\n",
    "           model.OutputLayer(loss=model.categorical_crossentropy)\n",
    "\n",
    "my_history = my_model.fit(xs, ys, alpha=0.02, epochs=100, batch_size=20)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressie: lineaire regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('numeric', noise=0.5)\n",
    "my_model = model.LinearRegression(dim=2)\n",
    "my_model.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressie: neuraal netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.concentric(noise=0.1)\n",
    "my_model = model.InputLayer(2) + \\\n",
    "           model.Dense(20) + \\\n",
    "           model.Activation(20, activation=model.tanh) + \\\n",
    "           model.Dense(10) + \\\n",
    "           model.Activation(10, activation=model.tanh) + \\\n",
    "           model.Dense(1) + \\\n",
    "           model.OutputLayer(loss=model.mean_squared_error)\n",
    "\n",
    "my_history = my_model.fit(xs, ys, alpha=0.005, epochs=100, batch_size=20)\n",
    "data.scatter(xs, ys, model=my_model)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Deel_B'>Deel B</a>\n",
    "\n",
    "In dit deel ga je met een klassieke dataset aan de slag, de [MNIST database](https://en.wikipedia.org/wiki/MNIST_database) die bestaat uit duizenden afbeeldingen van handgeschreven cijfers 0 tot en met 9. Dit wordt wel eens betiteld als het *Hello world!* voorbeeld uit de wereld van deep learning. Beschikbaar op BlackBoard is een bestand **MNIST_mini.dat** (dat je dient te unzippen uit **MNIST_mini.zip**) met een geminiaturiseerde versie met afbeeldingen van 12x12 pixels elk. In totaal zijn er maximaal 60.000 instances beschikbaar, 6.000 van elk cijfer. De functie `data.mnist_mini()` kan gebruikt worden om een aantal instances op te vragen. Deze functie levert de attributen van de instances in de vorm van 144 pixel-intensiteiten tussen 0 en 1, en de klasselabels in de vorm van 10 getalwaarden met het juiste cijfer als een one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(data.mnist_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiervan genereren we aanvankelijk om het simpel te houden slechts honderd instances elk voor de trainings-, validatie- en testdata. Onderzoek zelf de organisatie van deze data nader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 1: DATAGENERATIE\n",
    "xs, ys = data.mnist_mini('./MNIST_mini.dat', num=300)\n",
    "trn_xs, trn_ys = xs[  0:100], ys[  0:100]\n",
    "val_xs, val_ys = xs[100:200], ys[100:200]\n",
    "tst_xs, tst_ys = xs[200:300], ys[200:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder wordt een dummy model aangemaakt dat in dit geval bestaat uit een input, een hidden, en een outputlayer. Er is weliswaar vanalles aan te merken op dit overgesimplificeerde model, maar hanteer dit als een eerste uitgangspunt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 2: MODELDEFINITIE\n",
    "my_model = model.InputLayer(144, name='input') + \\\n",
    "           model.Dense(10, name='hidden') + \\\n",
    "           model.OutputLayer(name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens trainen en evalueren we dit model als volgt. Wederom zijn de gekozen parameters ongetwijfeld niet optimaal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 3: TRAINING\n",
    "my_history = my_model.fit(trn_xs, \n",
    "                          trn_ys, \n",
    "                          alpha=1e-2, \n",
    "                          epochs=3, \n",
    "                          batch_size=1, \n",
    "                          validation_data=(val_xs, val_ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echter, hiermee kunnen we een validatiecurve construeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 4: VALIDATIECURVE\n",
    "data.curve(my_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om inzicht te krijgen in de prestaties van het model, worden hieronder twintig instances uit de testdata getoond met voor en na de pijl respectievelijk de juiste en de voorspelde klasselabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 5: VISUALISATIE\n",
    "data.digits(tst_xs[:20], tst_ys[:20], model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berekenen we eens de gemiddelde loss op alle testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 6: EVALUATIE\n",
    "print(f'Loss: {my_model.evaluate(tst_xs, tst_ys)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit getal zegt misschien nog niet zoveel. Daarom bekijken we een grafische weergave van de [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) die weergeeft welke voorspelde klasselabels op de $x$-as aan alle echte klasselabels op de $y$-as worden toegekend (let op de logaritmische kleurschaal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 7: CONFUSIONMATRIX\n",
    "data.confusion(tst_xs, tst_ys, model=my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoewel er best wat fouten worden gemaakt liggen er toch behoorlijk wat juist geclassificeerde instances op de diagonaal. Daarnaast, een aantal van de meest gemaakte fouten betreft cijfers dit ook wel enigszins op elkaar lijken. Dit overdreven simpele model bereikt - afhankelijk van de willekeurig gekozen instances en initialisatiewaarden - een nauwkeurigheid van rond de 50%, wat wil zeggen dat ongeveer de helft van de cijfers correct wordt herkend. Dit is nog niet indrukwekkend goed, maar gezien de eenvoudige opbouw van het model al best verrassend en in elk geval ruim boven de 10% nauwkeurigheid die je mag verwachten op grond van kans alleen.\n",
    "\n",
    "Pas nu hieronder eens het bovenstaande model aan tot een neuraal netwerk dat deze afbeeldingen redelijk betrouwbaar kan classificeren. Kies zelf een geschikte opzet van het model en bepaal door te experimenteren geschikte waarden voor de diverse parameters. Voer dezelfde zeven stappen uit als hierboven, maar dan met een effectiever en beter geoptimaliseerd model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verander deze cel niet\n",
    "starttime = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 1: DATAGENERATIE\n",
    "xs, ys = data.mnist_mini('./MNIST_mini.dat', num=15000)\n",
    "trn_xs, trn_ys = xs[  0:10000], ys[  0:10000]\n",
    "val_xs, val_ys = xs[10000:12500], ys[10000:12500]\n",
    "tst_xs, tst_ys = xs[12500:15000], ys[12500:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 2: MODELDEFINITIE\n",
    "my_model = model.InputLayer(144, name='input') + \\\n",
    "           model.Dense(30, name='softplus') + \\\n",
    "           model.Activation(30, activation=model.softplus) + \\\n",
    "           model.Dense(30, name='tanh_1') + \\\n",
    "           model.Activation(30, activation=model.tanh) + \\\n",
    "           model.Dense(30, name='tanh_2') + \\\n",
    "           model.Activation(30, activation=model.tanh) + \\\n",
    "           model.Dense(10, name='softmax') + \\\n",
    "           model.Softmax(10) + \\\n",
    "           model.OutputLayer(loss=model.categorical_crossentropy, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 3: TRAINING\n",
    "my_history = my_model.fit(trn_xs, \n",
    "                          trn_ys, \n",
    "                          alpha=0.001, \n",
    "                          epochs=15, \n",
    "                          batch_size=100, \n",
    "                          validation_data=(val_xs, val_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 4: VALIDATIECURVE\n",
    "data.curve(my_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 5: VISUALISATIE\n",
    "data.digits(tst_xs[:20], tst_ys[:20], model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 6: EVALUATIE\n",
    "print(f'Loss: {my_model.evaluate(tst_xs, tst_ys)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STAP 7: CONFUSIONMATRIX\n",
    "data.confusion(tst_xs, tst_ys, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verander deze cel niet\n",
    "print(f'Verstreken tijd: {(time() - starttime) / 60.0:.1f} minuten.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Hint:**<br />Voer achtereenvolgens de onderstaande ontwikkelstappen uit.</div>\n",
    "\n",
    "* creëer eerst een model met meerdere hidden layers waarin gezamenlijk om en nabij een honderdtal neuronen verwerkt zijn;\n",
    "\n",
    "* stel dan de invoer- & uitvoerlagen en activatie- & loss-functies zo in dat het model geschikt is voor deze classificatie-taak;\n",
    "\n",
    "* begin met een datasetje van zeer beperkte grootte zodat het model in niet meer dan ongeveer een minuut over een klein aantal epochs te trainen is;\n",
    "\n",
    "* kies een grootte voor de mini-batches die naar jouw inschatting net genoeg is om een enigszins representatieve steekproef van de data te vormen;\n",
    "\n",
    "* probeer aanvankelijk een relatief grote learning rate uit en stel deze bij naar beneden zolang het model niet in staat is een dalende validatie-curve te tonen;\n",
    "\n",
    "* start met enkele epochs en voer dit op totdat de validatiecurve aangeeft dat het model redelijk getraind raakt (de trainingstijd neemt hierbij evenredig toe);\n",
    "\n",
    "* vergroot dan geleidelijk de grootte van de datasets (waarbij het nodige aantal epochs afneemt omdat er per epoch meer mini-batches getraind worden);\n",
    "\n",
    "* je mag alle 60.000 instances uiteindelijk gebruiken, maar dat is niet verplicht;\n",
    "\n",
    "* speel met de bovenstaande procedure tot je een model hebt gevonden dat in een werkbare tijd toch naar tevredenheid convergeert.\n",
    "\n",
    "<div class=\"alert alert-info\">**Opmerking:**<br />Ter indicatie, een deugdelijk model is in zijn uiteindelijke vorm op een typische hedendaagse CPU na enkele tientallen minuten training (eis: maximaal 1 uur) in staat om ruim 90% (eis: minimaal 80%) accuracy te behalen zonder daarbij zichtbaar te overfitten.</div>\n",
    "\n",
    "### <a id='Afsluiting'>Afsluiting</a>\n",
    "\n",
    "Als je klaar bent, lever dan je uitwerkingen als volgt in:\n",
    "\n",
    "1. Sla je model vanuit je code-editor op als **model.py**;\n",
    "\n",
    "2. Evalueer dit notebook door vanuit het menu *Kernel > Restart & Run All* te kiezen;\n",
    "\n",
    "3. Controleer dat alle uitvoer correct en volledig wordt geproduceerd;\n",
    "\n",
    "4. Exporteer dit notebook als **eindopdracht.html** vanuit het menu *File > Download as > HTML (.html)*;\n",
    "\n",
    "5. Verwijder vervolgens de uitvoer in dit notebook via het menu *Cell > All Output > Clear*;\n",
    "\n",
    "6. Sla dit notebook op als **eindopdracht.ipynb** middels het menu *File > Save and Checkpoint*;\n",
    "\n",
    "7. Comprimeer alledrie de hierboven genoemde bestanden in één bestand **eindopdracht.zip**;\n",
    "\n",
    "8. Lever je zip-bestand uiterlijk **vrijdag 17 april 2020** in op BlackBoard;\n",
    "\n",
    "9. E-mail de docent met je voorkeurstijdstippen voor het mondelinge tentamen.\n",
    "\n",
    "<div class=\"alert alert-danger\">**Waarschuwing:**<br />Verifieer dat je het juiste bestand uploadt, want eenmaal ingestuurd werk geldt als definitief en kan *niet* meer worden gewijzigd!</div>\n",
    "\n",
    "Succes!\n",
    "\n",
    "***\n",
    "\n",
    "<small>&copy; 2020, Dave R.M. Langers, [d.r.m.langers@pl.hanze.nl](mailto:d.r.m.langers@pl.hanze.nl)</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
